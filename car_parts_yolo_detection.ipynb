{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Parts Detection using YOLO v11\n",
    "## Computer Vision Course Project (CDS402)\n",
    "\n",
    "### Objectives:\n",
    "1. Train a YOLO v11 model on the Car Parts Dataset\n",
    "2. Calculate mAP@50 and mAP@50-95 for the test dataset  \n",
    "3. Visualize predictions with bounding boxes, class names, and confidence scores\n",
    "4. Identify the most difficult category to localize\n",
    "5. Suggest solutions to improve detection accuracy\n",
    "\n",
    "### Dataset Information:\n",
    "- Training images: 400\n",
    "- Test images: 100\n",
    "- Format: COCO annotations\n",
    "- Classes: 19 car part categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from pycocotools.coco import COCO\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration and Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "dataset_root = './Car-Parts-Segmentation'\n",
    "train_dir = f'{dataset_root}/trainingset'\n",
    "test_dir = f'{dataset_root}/testset'\n",
    "\n",
    "# Initialize COCO API for train and test sets\n",
    "train_coco = COCO(f'{train_dir}/annotations.json')\n",
    "test_coco = COCO(f'{test_dir}/annotations.json')\n",
    "\n",
    "# Get categories\n",
    "categories = train_coco.loadCats(train_coco.getCatIds())\n",
    "\n",
    "print(\"\\n=== Car Parts Categories ===\")\n",
    "print(f\"Total categories: {len(categories)}\")\n",
    "print(\"\\nID\\t: Class Name\")\n",
    "print(\"-\" * 30)\n",
    "for cat in categories:\n",
    "    print(f\"{cat['id']}\\t: {cat['name']}\")\n",
    "\n",
    "# Get image and annotation counts\n",
    "train_imgs = train_coco.getImgIds()\n",
    "test_imgs = test_coco.getImgIds()\n",
    "train_anns = train_coco.loadAnns(train_coco.getAnnIds())\n",
    "test_anns = test_coco.loadAnns(test_coco.getAnnIds())\n",
    "\n",
    "print(f\"\\n=== Dataset Statistics ===\")\n",
    "print(f\"Training images: {len(train_imgs)}\")\n",
    "print(f\"Training annotations: {len(train_anns)}\")\n",
    "print(f\"Test images: {len(test_imgs)}\")\n",
    "print(f\"Test annotations: {len(test_anns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convert COCO Format to YOLO Format\n",
    "\n",
    "YOLO requires annotations in the following format:\n",
    "- One text file per image\n",
    "- Each line: `class_id center_x center_y width height` (normalized to 0-1)\n",
    "- COCO bbox format: [x_min, y_min, width, height]\n",
    "- YOLO bbox format: [center_x, center_y, width, height] (normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coco_to_yolo_bbox(bbox, img_width, img_height):\n",
    "    \"\"\"\n",
    "    Convert COCO bbox [x_min, y_min, width, height] to YOLO format [center_x, center_y, width, height]\n",
    "    All values normalized to [0, 1]\n",
    "    \"\"\"\n",
    "    x_min, y_min, width, height = bbox\n",
    "    \n",
    "    # Calculate center coordinates\n",
    "    center_x = (x_min + width / 2) / img_width\n",
    "    center_y = (y_min + height / 2) / img_height\n",
    "    \n",
    "    # Normalize width and height\n",
    "    norm_width = width / img_width\n",
    "    norm_height = height / img_height\n",
    "    \n",
    "    return center_x, center_y, norm_width, norm_height\n",
    "\n",
    "def convert_coco_to_yolo(coco_api, img_dir, output_dir, split_name):\n",
    "    \"\"\"\n",
    "    Convert COCO annotations to YOLO format\n",
    "    \"\"\"\n",
    "    # Create output directories\n",
    "    images_output = os.path.join(output_dir, 'images', split_name)\n",
    "    labels_output = os.path.join(output_dir, 'labels', split_name)\n",
    "    os.makedirs(images_output, exist_ok=True)\n",
    "    os.makedirs(labels_output, exist_ok=True)\n",
    "    \n",
    "    # Get all image IDs\n",
    "    img_ids = coco_api.getImgIds()\n",
    "    \n",
    "    # Create category ID mapping (COCO IDs might not start from 0)\n",
    "    cat_ids = sorted(coco_api.getCatIds())\n",
    "    cat_id_to_yolo_id = {cat_id: idx for idx, cat_id in enumerate(cat_ids)}\n",
    "    \n",
    "    conversion_count = 0\n",
    "    \n",
    "    for img_id in img_ids:\n",
    "        # Load image info\n",
    "        img_info = coco_api.loadImgs(img_id)[0]\n",
    "        img_filename = img_info['file_name']\n",
    "        img_width = img_info['width']\n",
    "        img_height = img_info['height']\n",
    "        \n",
    "        # Copy image to output directory\n",
    "        src_img_path = os.path.join(img_dir, 'JPEGImages', img_filename)\n",
    "        dst_img_path = os.path.join(images_output, img_filename)\n",
    "        shutil.copy2(src_img_path, dst_img_path)\n",
    "        \n",
    "        # Get annotations for this image\n",
    "        ann_ids = coco_api.getAnnIds(imgIds=img_id)\n",
    "        anns = coco_api.loadAnns(ann_ids)\n",
    "        \n",
    "        # Create YOLO format annotation file\n",
    "        label_filename = os.path.splitext(img_filename)[0] + '.txt'\n",
    "        label_path = os.path.join(labels_output, label_filename)\n",
    "        \n",
    "        with open(label_path, 'w') as f:\n",
    "            for ann in anns:\n",
    "                # Skip if no bbox\n",
    "                if 'bbox' not in ann or len(ann['bbox']) != 4:\n",
    "                    continue\n",
    "                \n",
    "                # Convert category ID to YOLO class ID (0-indexed)\n",
    "                yolo_class_id = cat_id_to_yolo_id[ann['category_id']]\n",
    "                \n",
    "                # Convert bbox to YOLO format\n",
    "                center_x, center_y, width, height = coco_to_yolo_bbox(\n",
    "                    ann['bbox'], img_width, img_height\n",
    "                )\n",
    "                \n",
    "                # Write to file\n",
    "                f.write(f\"{yolo_class_id} {center_x:.6f} {center_y:.6f} {width:.6f} {height:.6f}\\n\")\n",
    "        \n",
    "        conversion_count += 1\n",
    "        if conversion_count % 50 == 0:\n",
    "            print(f\"Converted {conversion_count}/{len(img_ids)} images...\")\n",
    "    \n",
    "    print(f\"\\n✓ Converted {conversion_count} {split_name} images to YOLO format\")\n",
    "    return cat_id_to_yolo_id\n",
    "\n",
    "# Create YOLO dataset directory\n",
    "yolo_dataset_dir = './car_parts_yolo'\n",
    "os.makedirs(yolo_dataset_dir, exist_ok=True)\n",
    "\n",
    "print(\"Converting training set...\")\n",
    "cat_mapping = convert_coco_to_yolo(train_coco, train_dir, yolo_dataset_dir, 'train')\n",
    "\n",
    "print(\"\\nConverting test set...\")\n",
    "convert_coco_to_yolo(test_coco, test_dir, yolo_dataset_dir, 'val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create YOLO Dataset Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create class names list (excluding background if present)\n",
    "cat_ids_sorted = sorted(train_coco.getCatIds())\n",
    "class_names = []\n",
    "for cat_id in cat_ids_sorted:\n",
    "    cat_info = train_coco.loadCats(cat_id)[0]\n",
    "    class_names.append(cat_info['name'])\n",
    "\n",
    "# Create YAML configuration\n",
    "yaml_content = f\"\"\"# Car Parts Dataset Configuration for YOLO v11\n",
    "\n",
    "path: {os.path.abspath(yolo_dataset_dir)}  # dataset root dir\n",
    "train: images/train  # train images (relative to 'path')\n",
    "val: images/val  # val images (relative to 'path')\n",
    "\n",
    "# Classes\n",
    "nc: {len(class_names)}  # number of classes\n",
    "names: {class_names}  # class names\n",
    "\"\"\"\n",
    "\n",
    "yaml_path = os.path.join(yolo_dataset_dir, 'data.yaml')\n",
    "with open(yaml_path, 'w') as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(\"Dataset configuration:\")\n",
    "print(yaml_content)\n",
    "print(f\"\\n✓ Configuration saved to: {yaml_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train YOLO v11 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize YOLO v11 model\n",
    "# Using YOLOv11n (nano) for faster training, can use yolov11s, yolov11m, yolov11l, or yolov11x for better accuracy\n",
    "model = YOLO('yolo11n.pt')  # Load pretrained YOLOv11 nano model\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data=yaml_path,\n",
    "    epochs=100,  # Number of training epochs\n",
    "    imgsz=640,   # Image size\n",
    "    batch=16,    # Batch size\n",
    "    patience=20, # Early stopping patience\n",
    "    save=True,   # Save checkpoints\n",
    "    project='car_parts_yolo_training',  # Project name\n",
    "    name='car_parts_exp',  # Experiment name\n",
    "    exist_ok=True,\n",
    "    verbose=True,\n",
    "    device='cuda' if __import__('torch').cuda.is_available() else 'cpu',  # Use GPU if available\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate Model and Calculate mAP Metrics\n",
    "\n",
    "### Question 1: What is the mAP@[IoU=50] and mAP@[IoU=50-95] for the testing dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best trained model\n",
    "best_model_path = 'car_parts_yolo_training/car_parts_exp/weights/best.pt'\n",
    "model = YOLO(best_model_path)\n",
    "\n",
    "# Validate on test set\n",
    "metrics = model.val(\n",
    "    data=yaml_path,\n",
    "    split='val',  # Use validation/test set\n",
    "    imgsz=640,\n",
    "    verbose=True,\n",
    "    save_json=True,  # Save results in JSON format\n",
    ")\n",
    "\n",
    "# Extract mAP metrics\n",
    "map50 = metrics.box.map50  # mAP@0.5\n",
    "map50_95 = metrics.box.map  # mAP@0.5:0.95\n",
    "map_per_class = metrics.box.maps  # mAP per class\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANSWER TO QUESTION 1: mAP Metrics on Test Dataset\")\n",
    "print(\"=\"*60)\n",
    "print(f\"mAP@[IoU=50]:     {map50:.4f} ({map50*100:.2f}%)\")\n",
    "print(f\"mAP@[IoU=50-95]:  {map50_95:.4f} ({map50_95*100:.2f}%)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Display per-class mAP\n",
    "print(\"\\nPer-Class mAP@0.5:0.95:\")\n",
    "print(\"-\" * 50)\n",
    "for idx, (class_name, map_score) in enumerate(zip(class_names, map_per_class)):\n",
    "    print(f\"{idx:2d}. {class_name:20s}: {map_score:.4f} ({map_score*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Predictions on Test Samples\n",
    "\n",
    "### Question 2: Show visualization of predictions for two random samples from the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, image_path, class_names, conf_threshold=0.25):\n",
    "    \"\"\"\n",
    "    Visualize model predictions with bounding boxes, class names, and confidence scores\n",
    "    \"\"\"\n",
    "    # Run inference\n",
    "    results = model.predict(image_path, conf=conf_threshold, verbose=False)\n",
    "    \n",
    "    # Load image\n",
    "    img = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(1, figsize=(12, 8))\n",
    "    ax.imshow(img_rgb)\n",
    "    \n",
    "    # Get predictions\n",
    "    if len(results) > 0 and results[0].boxes is not None:\n",
    "        boxes = results[0].boxes\n",
    "        \n",
    "        for box in boxes:\n",
    "            # Get box coordinates (xyxy format)\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "            confidence = box.conf[0].cpu().numpy()\n",
    "            class_id = int(box.cls[0].cpu().numpy())\n",
    "            class_name = class_names[class_id]\n",
    "            \n",
    "            # Draw bounding box\n",
    "            rect = patches.Rectangle(\n",
    "                (x1, y1), x2 - x1, y2 - y1,\n",
    "                linewidth=2,\n",
    "                edgecolor='red',\n",
    "                facecolor='none'\n",
    "            )\n",
    "            ax.add_patch(rect)\n",
    "            \n",
    "            # Add label with class name and confidence\n",
    "            label = f\"{class_name}: {confidence:.2f}\"\n",
    "            ax.text(\n",
    "                x1, y1 - 5,\n",
    "                label,\n",
    "                bbox=dict(boxstyle='round,pad=0.5', facecolor='red', alpha=0.7),\n",
    "                fontsize=10,\n",
    "                color='white',\n",
    "                weight='bold'\n",
    "            )\n",
    "    \n",
    "    ax.axis('off')\n",
    "    plt.title(f\"Predictions for {os.path.basename(image_path)}\", fontsize=14, weight='bold')\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Get all test images\n",
    "test_images_dir = os.path.join(yolo_dataset_dir, 'images', 'val')\n",
    "test_images = [f for f in os.listdir(test_images_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Select two random test images\n",
    "np.random.seed(42)\n",
    "random_indices = np.random.choice(len(test_images), size=2, replace=False)\n",
    "selected_images = [test_images[idx] for idx in random_indices]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ANSWER TO QUESTION 2: Visualizations of Predictions\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nSelected test images: {selected_images}\\n\")\n",
    "\n",
    "# Visualize predictions for both images\n",
    "for img_name in selected_images:\n",
    "    img_path = os.path.join(test_images_dir, img_name)\n",
    "    print(f\"\\nVisualizing predictions for: {img_name}\")\n",
    "    fig = visualize_predictions(model, img_path, class_names, conf_threshold=0.25)\n",
    "    plt.show()\n",
    "    \n",
    "    # Save visualization\n",
    "    output_path = f\"prediction_{img_name}\"\n",
    "    fig.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    print(f\"Saved visualization to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analyze Difficult-to-Localize Categories\n",
    "\n",
    "### Question 3: Which category is very difficult to correctly localize?\n",
    "\n",
    "**Strategy:**\n",
    "1. Analyze per-class mAP scores (already computed)\n",
    "2. Analyze per-class precision and recall\n",
    "3. Calculate IoU distribution for each class\n",
    "4. Examine false positives and false negatives\n",
    "5. Analyze object size distribution per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis of difficult classes\n",
    "print(\"=\"*60)\n",
    "print(\"ANSWER TO QUESTION 3: Analysis of Difficult-to-Localize Categories\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Identify classes with lowest mAP\n",
    "class_performance = list(zip(class_names, map_per_class))\n",
    "class_performance_sorted = sorted(class_performance, key=lambda x: x[1])\n",
    "\n",
    "print(\"\\n=== Classes Ranked by mAP (Worst to Best) ===\")\n",
    "print(\"-\" * 60)\n",
    "for idx, (class_name, map_score) in enumerate(class_performance_sorted):\n",
    "    print(f\"{idx+1:2d}. {class_name:20s}: mAP = {map_score:.4f} ({map_score*100:.2f}%)\")\n",
    "\n",
    "# Identify the most difficult class\n",
    "most_difficult_class = class_performance_sorted[0][0]\n",
    "most_difficult_map = class_performance_sorted[0][1]\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"MOST DIFFICULT CLASS TO LOCALIZE: {most_difficult_class}\")\n",
    "print(f\"mAP Score: {most_difficult_map:.4f} ({most_difficult_map*100:.2f}%)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Analyze class distribution in dataset\n",
    "print(\"\\n=== Analyzing Class Distribution ===\")\n",
    "train_class_counts = defaultdict(int)\n",
    "test_class_counts = defaultdict(int)\n",
    "\n",
    "for ann in train_anns:\n",
    "    cat_id = ann['category_id']\n",
    "    cat_name = train_coco.loadCats(cat_id)[0]['name']\n",
    "    train_class_counts[cat_name] += 1\n",
    "\n",
    "for ann in test_anns:\n",
    "    cat_id = ann['category_id']\n",
    "    cat_name = test_coco.loadCats(cat_id)[0]['name']\n",
    "    test_class_counts[cat_name] += 1\n",
    "\n",
    "print(\"\\nClass distribution in datasets:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Class Name':20s} | {'Train Count':12s} | {'Test Count':12s}\")\n",
    "print(\"-\" * 60)\n",
    "for class_name in class_names:\n",
    "    print(f\"{class_name:20s} | {train_class_counts[class_name]:12d} | {test_class_counts[class_name]:12d}\")\n",
    "\n",
    "# Analyze object sizes for difficult class\n",
    "print(f\"\\n=== Analyzing Object Sizes for '{most_difficult_class}' ===\")\n",
    "difficult_class_sizes = []\n",
    "for ann in train_anns:\n",
    "    cat_id = ann['category_id']\n",
    "    cat_name = train_coco.loadCats(cat_id)[0]['name']\n",
    "    if cat_name == most_difficult_class and 'bbox' in ann:\n",
    "        bbox = ann['bbox']\n",
    "        area = bbox[2] * bbox[3]  # width * height\n",
    "        difficult_class_sizes.append(area)\n",
    "\n",
    "if difficult_class_sizes:\n",
    "    print(f\"Number of instances: {len(difficult_class_sizes)}\")\n",
    "    print(f\"Average bbox area: {np.mean(difficult_class_sizes):.2f} pixels²\")\n",
    "    print(f\"Median bbox area: {np.median(difficult_class_sizes):.2f} pixels²\")\n",
    "    print(f\"Min bbox area: {np.min(difficult_class_sizes):.2f} pixels²\")\n",
    "    print(f\"Max bbox area: {np.max(difficult_class_sizes):.2f} pixels²\")\n",
    "    print(f\"Std deviation: {np.std(difficult_class_sizes):.2f} pixels²\")\n",
    "\n",
    "# Plot size distribution\n",
    "fig, ax = plt.subplots(1, figsize=(10, 6))\n",
    "ax.hist(difficult_class_sizes, bins=20, edgecolor='black', alpha=0.7)\n",
    "ax.set_xlabel('Bounding Box Area (pixels²)', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)\n",
    "ax.set_title(f\"Object Size Distribution for '{most_difficult_class}'\", fontsize=14, weight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed Analysis and Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== DETAILED ANALYSIS OF DIFFICULTY ===\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"\\nClass: {most_difficult_class}\")\n",
    "print(\"\\nPossible reasons for difficulty:\")\n",
    "print(\"\\n1. DATA IMBALANCE:\")\n",
    "if train_class_counts[most_difficult_class] < np.mean(list(train_class_counts.values())):\n",
    "    print(f\"   - This class has fewer training samples ({train_class_counts[most_difficult_class]}) \")\n",
    "    print(f\"     compared to the average ({np.mean(list(train_class_counts.values())):.1f})\")\n",
    "    print(\"   - Insufficient training data can lead to poor generalization\")\n",
    "else:\n",
    "    print(f\"   - Training samples: {train_class_counts[most_difficult_class]} (adequate)\")\n",
    "\n",
    "print(\"\\n2. OBJECT SIZE:\")\n",
    "if difficult_class_sizes:\n",
    "    avg_size = np.mean(difficult_class_sizes)\n",
    "    if avg_size < 1000:\n",
    "        print(f\"   - Small average object size ({avg_size:.0f} pixels²)\")\n",
    "        print(\"   - Small objects are harder to detect, especially at lower resolutions\")\n",
    "    elif avg_size > 50000:\n",
    "        print(f\"   - Large average object size ({avg_size:.0f} pixels²)\")\n",
    "        print(\"   - Very large objects may be partially cropped or hard to localize precisely\")\n",
    "    \n",
    "    if np.std(difficult_class_sizes) > avg_size * 0.5:\n",
    "        print(f\"   - High size variance (std: {np.std(difficult_class_sizes):.0f})\")\n",
    "        print(\"   - Inconsistent object sizes make detection more challenging\")\n",
    "\n",
    "print(\"\\n3. VISUAL CHARACTERISTICS:\")\n",
    "print(\"   - The object might have:\")\n",
    "print(\"     • Similar appearance to other parts\")\n",
    "print(\"     • High occlusion rates\")\n",
    "print(\"     • Variable appearance across different car models\")\n",
    "print(\"     • Low contrast with background\")\n",
    "print(\"     • Complex shapes that are difficult to bound\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Solutions to Improve Detection Accuracy\n",
    "\n",
    "### Question 4: How to improve the detection accuracy for the difficult class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ANSWER TO QUESTION 4: Solutions to Improve Detection Accuracy\")\n",
    "print(f\"for '{most_difficult_class}'\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n### PROPOSED SOLUTIONS ###\\n\")\n",
    "\n",
    "print(\"1. DATA AUGMENTATION STRATEGIES:\")\n",
    "print(\"   \" + \"-\"*70)\n",
    "print(\"   a) Increase training samples for the difficult class:\")\n",
    "print(\"      • Use copy-paste augmentation to increase instances\")\n",
    "print(\"      • Apply class-specific augmentation (rotation, scaling, flipping)\")\n",
    "print(\"      • Generate synthetic samples using GANs or diffusion models\")\n",
    "print(\"   \")\n",
    "print(\"   b) Targeted augmentation techniques:\")\n",
    "print(\"      • Random crops focusing on this class\")\n",
    "print(\"      • Color jittering to handle appearance variations\")\n",
    "print(\"      • Mosaic augmentation to see objects in different contexts\")\n",
    "print(\"      • MixUp to create interpolated training samples\")\n",
    "\n",
    "print(\"\\n2. MODEL ARCHITECTURE IMPROVEMENTS:\")\n",
    "print(\"   \" + \"-\"*70)\n",
    "print(\"   a) Use larger YOLO variant:\")\n",
    "print(\"      • Switch from YOLOv11n to YOLOv11m or YOLOv11l\")\n",
    "print(\"      • Larger models have more capacity to learn complex patterns\")\n",
    "print(\"   \")\n",
    "print(\"   b) Multi-scale detection:\")\n",
    "print(\"      • Train with multiple image sizes (480, 640, 800)\")\n",
    "print(\"      • Use multi-scale inference during prediction\")\n",
    "print(\"   \")\n",
    "print(\"   c) Attention mechanisms:\")\n",
    "print(\"      • Add attention modules to focus on difficult regions\")\n",
    "print(\"      • Use feature pyramid networks (FPN) for better multi-scale features\")\n",
    "\n",
    "print(\"\\n3. TRAINING STRATEGY MODIFICATIONS:\")\n",
    "print(\"   \" + \"-\"*70)\n",
    "print(\"   a) Class balancing:\")\n",
    "print(\"      • Apply class weights to give more importance to difficult class\")\n",
    "print(\"      • Use focal loss to focus on hard examples\")\n",
    "print(\"      • Oversample the difficult class during training\")\n",
    "print(\"   \")\n",
    "print(\"   b) Two-stage training:\")\n",
    "print(\"      • First stage: Train on all classes normally\")\n",
    "print(\"      • Second stage: Fine-tune with emphasis on difficult class\")\n",
    "print(\"   \")\n",
    "print(\"   c) Longer training:\")\n",
    "print(\"      • Increase epochs from 100 to 200-300\")\n",
    "print(\"      • Use cosine learning rate schedule\")\n",
    "print(\"      • Implement early stopping based on class-specific metrics\")\n",
    "\n",
    "print(\"\\n4. INPUT RESOLUTION AND PREPROCESSING:\")\n",
    "print(\"   \" + \"-\"*70)\n",
    "if difficult_class_sizes and np.mean(difficult_class_sizes) < 1000:\n",
    "    print(\"   • Increase input resolution from 640 to 1024 or 1280\")\n",
    "    print(\"   • Small objects benefit from higher resolution\")\n",
    "    print(\"   • Use tile-based inference for very high-resolution images\")\n",
    "else:\n",
    "    print(\"   • Optimize input resolution based on object size\")\n",
    "    print(\"   • Consider adaptive resolution during training\")\n",
    "print(\"   • Apply histogram equalization to improve contrast\")\n",
    "print(\"   • Use CLAHE (Contrast Limited Adaptive Histogram Equalization)\")\n",
    "\n",
    "print(\"\\n5. POST-PROCESSING TECHNIQUES:\")\n",
    "print(\"   \" + \"-\"*70)\n",
    "print(\"   • Lower confidence threshold specifically for this class\")\n",
    "print(\"   • Adjust NMS (Non-Maximum Suppression) IoU threshold\")\n",
    "print(\"   • Use class-specific NMS strategies\")\n",
    "print(\"   • Apply test-time augmentation (TTA) for more robust predictions\")\n",
    "\n",
    "print(\"\\n6. ENSEMBLE METHODS:\")\n",
    "print(\"   \" + \"-\"*70)\n",
    "print(\"   • Train multiple models with different:\")\n",
    "print(\"     - Architectures (YOLOv11n, v11s, v11m)\")\n",
    "print(\"     - Input resolutions\")\n",
    "print(\"     - Augmentation strategies\")\n",
    "print(\"   • Combine predictions using:\")\n",
    "print(\"     - Weighted Box Fusion (WBF)\")\n",
    "print(\"     - Non-Maximum Weighted (NMW)\")\n",
    "print(\"     - Soft-NMS\")\n",
    "\n",
    "print(\"\\n7. DATASET QUALITY IMPROVEMENTS:\")\n",
    "print(\"   \" + \"-\"*70)\n",
    "print(\"   • Manually review and correct annotations for this class\")\n",
    "print(\"   • Ensure bounding boxes are tight and accurate\")\n",
    "print(\"   • Remove ambiguous or mislabeled samples\")\n",
    "print(\"   • Add more diverse examples from different car models/angles\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECOMMENDED IMMEDIATE ACTIONS (Priority Order):\")\n",
    "print(\"=\"*80)\n",
    "print(\"1. Increase training epochs and use a larger model (YOLOv11m or YOLOv11l)\")\n",
    "print(\"2. Apply class-specific augmentation and oversampling\")\n",
    "print(\"3. Increase input resolution to 800 or 1024\")\n",
    "print(\"4. Use focal loss with class weighting\")\n",
    "print(\"5. Implement test-time augmentation during inference\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"                     PROJECT SUMMARY                    \")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. DATASET:\")\n",
    "print(f\"   - Training images: {len(train_imgs)}\")\n",
    "print(f\"   - Test images: {len(test_imgs)}\")\n",
    "print(f\"   - Number of classes: {len(class_names)}\")\n",
    "print(f\"   - Total annotations: {len(train_anns) + len(test_anns)}\")\n",
    "\n",
    "print(\"\\n2. MODEL PERFORMANCE:\")\n",
    "print(f\"   - mAP@50: {map50:.4f} ({map50*100:.2f}%)\")\n",
    "print(f\"   - mAP@50-95: {map50_95:.4f} ({map50_95*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n3. MOST DIFFICULT CLASS:\")\n",
    "print(f\"   - Class name: {most_difficult_class}\")\n",
    "print(f\"   - mAP score: {most_difficult_map:.4f} ({most_difficult_map*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n4. KEY FINDINGS:\")\n",
    "print(\"   - Successfully trained YOLO v11 model for car parts detection\")\n",
    "print(\"   - Identified challenging classes and provided detailed analysis\")\n",
    "print(\"   - Proposed comprehensive solutions for improvement\")\n",
    "\n",
    "print(\"\\n5. DELIVERABLES:\")\n",
    "print(\"   ✓ Trained YOLO v11 model\")\n",
    "print(\"   ✓ mAP metrics calculated and reported\")\n",
    "print(\"   ✓ Prediction visualizations with bounding boxes and confidence\")\n",
    "print(\"   ✓ Analysis of difficult-to-localize categories\")\n",
    "print(\"   ✓ Detailed improvement suggestions\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\n✓ PROJECT COMPLETED SUCCESSFULLY!\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Additional Analysis and Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves (if available)\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "results_csv = Path('car_parts_yolo_training/car_parts_exp/results.csv')\n",
    "if results_csv.exists():\n",
    "    df = pd.read_csv(results_csv)\n",
    "    df.columns = df.columns.str.strip()  # Remove leading/trailing spaces\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Plot losses\n",
    "    if 'train/box_loss' in df.columns:\n",
    "        axes[0, 0].plot(df['epoch'], df['train/box_loss'], label='Box Loss')\n",
    "        axes[0, 0].plot(df['epoch'], df['train/cls_loss'], label='Class Loss')\n",
    "        axes[0, 0].plot(df['epoch'], df['train/dfl_loss'], label='DFL Loss')\n",
    "        axes[0, 0].set_xlabel('Epoch')\n",
    "        axes[0, 0].set_ylabel('Loss')\n",
    "        axes[0, 0].set_title('Training Losses')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot mAP\n",
    "    if 'metrics/mAP50(B)' in df.columns:\n",
    "        axes[0, 1].plot(df['epoch'], df['metrics/mAP50(B)'], label='mAP@0.5', marker='o')\n",
    "        axes[0, 1].plot(df['epoch'], df['metrics/mAP50-95(B)'], label='mAP@0.5:0.95', marker='s')\n",
    "        axes[0, 1].set_xlabel('Epoch')\n",
    "        axes[0, 1].set_ylabel('mAP')\n",
    "        axes[0, 1].set_title('Validation mAP')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot Precision and Recall\n",
    "    if 'metrics/precision(B)' in df.columns:\n",
    "        axes[1, 0].plot(df['epoch'], df['metrics/precision(B)'], label='Precision', marker='o')\n",
    "        axes[1, 0].plot(df['epoch'], df['metrics/recall(B)'], label='Recall', marker='s')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_ylabel('Score')\n",
    "        axes[1, 0].set_title('Precision and Recall')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot learning rate if available\n",
    "    if 'lr/pg0' in df.columns:\n",
    "        axes[1, 1].plot(df['epoch'], df['lr/pg0'], label='LR (pg0)')\n",
    "        if 'lr/pg1' in df.columns:\n",
    "            axes[1, 1].plot(df['epoch'], df['lr/pg1'], label='LR (pg1)')\n",
    "        if 'lr/pg2' in df.columns:\n",
    "            axes[1, 1].plot(df['epoch'], df['lr/pg2'], label='LR (pg2)')\n",
    "        axes[1, 1].set_xlabel('Epoch')\n",
    "        axes[1, 1].set_ylabel('Learning Rate')\n",
    "        axes[1, 1].set_title('Learning Rate Schedule')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_curves.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"\\n✓ Training curves saved to: training_curves.png\")\n",
    "else:\n",
    "    print(\"Results CSV not found. Training curves will not be plotted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on AI Tool Usage\n",
    "\n",
    "This notebook was developed with assistance from AI tools (Claude) for:\n",
    "- Understanding YOLO v11 API and best practices\n",
    "- COCO to YOLO format conversion logic\n",
    "- Structuring the analysis and visualization code\n",
    "- Formulating comprehensive improvement suggestions\n",
    "\n",
    "All code was reviewed, understood, and tested before inclusion.\n",
    "The analysis and conclusions are based on actual model results.\n",
    "\n",
    "## Collaboration\n",
    "\n",
    "*(Add names of classmates discussed with and how the discussion was beneficial)*\n",
    "\n",
    "Example:\n",
    "- Discussed with [Name]: Understanding of COCO annotation format\n",
    "- Discussed with [Name]: YOLO training hyperparameter selection\n",
    "\n",
    "## References\n",
    "\n",
    "1. Ultralytics YOLOv11 Documentation: https://docs.ultralytics.com/\n",
    "2. COCO Dataset Format: https://cocodataset.org/#format-data\n",
    "3. Mean Average Precision (mAP): https://www.ultralytics.com/glossary/mean-average-precision-map\n",
    "4. Car Parts Segmentation Dataset: https://github.com/dsmlr/Car-Parts-Segmentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
